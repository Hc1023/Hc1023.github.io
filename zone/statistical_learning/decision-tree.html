<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>decision-tree</title></head>
<body><h1>决策树</h1>
<h2>数据的表示</h2>
<h3>数据特征</h3>
<p>算法如何“看”数据，<strong>特征</strong>是我们可以向这些数据提出的问题<span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.711ex" height="2.577ex" viewBox="0 -806.1 4181.2 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="0" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="692" y="-213"></use><use xlink:href="#E1-MJMAIN-2C" x="943" y="0"></use><use xlink:href="#E1-MJMAIN-2E" x="1388" y="0"></use><use xlink:href="#E1-MJMAIN-2E" x="1832" y="0"></use><use xlink:href="#E1-MJMAIN-2E" x="2277" y="0"></use><use xlink:href="#E1-MJMAIN-2C" x="2722" y="0"></use><g transform="translate(3166,0)"><use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="692" y="-213"></use></g></g></svg></span><script type="math/tex">f_1,...,f_n</script>，例如颜色、形状。</p>
<p>对分类问题，在学习/训练/归纳的时候，基于特征拟合一个分类器模型。模型可以根据特征对新的数据分类。</p>
<h3>数据生成分布</h3>
<ul>
<li>我们要用<strong>概率模型</strong>去学习</li>
<li>数据/标签对服从某种概率分布，称为<strong>数据的生成分布</strong></li>

</ul>
<p>概率分布：描述某些事件的可能性，所有可能的结果及其发生的概率。</p>
<h2>决策树</h2>
<ul>
<li>树的内部节点用特征作标签</li>
<li>树枝用是否符合特征来标签</li>
<li>叶子为类别标签</li>

</ul>
<p>递归法：计算每个特征的“得分”，选择分数最高的特征，根据该特征的数值对数据进行划分并递归调用。</p>
<p>得分可以用训练误差（训练集上的平均误差率）衡量，对于分类问题，最常见的“误差”是错分的个数。</p>
<h2>过拟合</h2>
<p>递归法截止条件</p>
<p>基本情况：如果所有数据属于同一类，使用该标签创建叶节点或者所有数据有相同的特征。</p>
<p><strong>过拟合</strong>发生在模型太过偏向训练数据时，目标是学习一个一般的模型，既要符合训练数据也要符合其他数据（比如测试数据）</p>
<h3>阻止过拟合</h3>
<p>递归法截止条件除基本情况外，还可以包括树达到一定深度、剩下一定数量/比例的数据、足够小训练误差、使用验证数据等。</p>
<ul>
<li>修剪</li>

</ul>
<p>树构建之后，返回并“修剪”树，即移除树的一些底层部分。类似于提前停止，但在整个树构建好以后完成。</p>
<ul>
<li>规则：正则化方法</li>

</ul>
<h3>处理非二分值特征</h3>
<ul>
<li>多值特征：处理成多个划分，处理成多个二值划分</li>
<li>实值特征：用比较或范围划分</li>

</ul>
<h3>划分数据特征的得分</h3>
<ul>
<li>训练误差</li>
<li>基尼系数：划分后标签比例的平方和</li>
<li>熵：划分后标签分布的不确定性</li>

</ul>
<p>敏感度：熵&gt;基尼系数&gt;训练误差</p>
<p>&nbsp;</p>
</body>
</html>